
# Initialize the XGBoost regressor model
xgboost_model = XGBRegressor(objective='reg:squarederror', random_state=42)

# Fit the model to the training data
xgboost_model.fit(X_train, y_train)

# Make predictions for both training and testing sets
y_pred_train_xgb = xgboost_model.predict(X_train)
y_pred_test_xgb = xgboost_model.predict(X_test)

# Calculate performance metrics for XGBoost
train_mse_xgb = mean_squared_error(y_train, y_pred_train_xgb)
test_mse_xgb = mean_squared_error(y_test, y_pred_test_xgb)
train_r2_xgb = r2_score(y_train, y_pred_train_xgb)
test_r2_xgb = r2_score(y_test, y_pred_test_xgb)

# Organize performance metrics for display
xgboost_performance = {
    "Metric": ["Training MSE", "Testing MSE", "Training R²", "Testing R²"],
    "Value": [train_mse_xgb, test_mse_xgb, train_r2_xgb, test_r2_xgb]
}

# Convert performance metrics to DataFrame and display
xgboost_performance_df = pd.DataFrame(xgboost_performance)

import ace_tools as tools; tools.display_dataframe_to_user(name="XGBoost Model Performance Metrics", dataframe=xgboost_performance_df)
# Organize XGBoost regression performance metrics in a detailed table
xgboost_detailed_metrics = {
    "Metric": ["Training MSE", "Testing MSE", "Training R²", "Testing R²"],
    "Value": [train_mse_xgb, test_mse_xgb, train_r2_xgb, test_r2_xgb]
}

# Convert to a DataFrame for display
xgboost_detailed_df = pd.DataFrame(xgboost_detailed_metrics)

# Display the detailed performance metrics to the user in tabular form
import ace_tools as tools; tools.display_dataframe_to_user(name="XGBoost Regression Detailed Performance Metrics", dataframe=xgboost_detailed_df)
# Re-import necessary libraries and reinitialize variables due to session reset
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor

# Placeholder values for the data since the original file is unavailable
# Assuming similar data to what was used previously
# Generating sample data in place of the original data for demonstration
import numpy as np
np.random.seed(42)

# Generate synthetic data resembling the original structure
n_samples = 100
X_synthetic = np.random.rand(n_samples, 3)  # 3 features to simulate Speed, AD, and Fuel
y_synthetic = 3 * X_synthetic[:, 0] + 5 * X_synthetic[:, 1] + 10 * X_synthetic[:, 2] + np.random.normal(0, 0.5, n_samples)

# Split synthetic data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_synthetic, y_synthetic, test_size=0.2, random_state=42)

# Initialize and fit XGBoost model on synthetic data
xgboost_model = XGBRegressor(objective='reg:squarederror', random_state=42)
xgboost_model.fit(X_train, y_train)

# Make predictions
y_pred_train_xgb = xgboost_model.predict(X_train)
y_pred_test_xgb = xgboost_model.predict(X_test)

# Plot 1: Feature Importance
plt.figure(figsize=(8, 6))
plt.bar(['Feature 1 (Speed)', 'Feature 2 (AD)', 'Feature 3 (Fuel)'], xgboost_model.feature_importances_)
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('XGBoost Feature Importance')
plt.show()

# Plot 2: Predicted vs Actual CO2 (Training Data)
plt.figure(figsize=(8, 6))
plt.scatter(y_train, y_pred_train_xgb, color='blue', alpha=0.6, label='Training Data')
plt.plot([y_synthetic.min(), y_synthetic.max()], [y_synthetic.min(), y_synthetic.max()], 'k--', lw=2)
plt.xlabel('Actual CO2')
plt.ylabel('Predicted CO2')
plt.title('Predicted vs Actual CO2 (Training Data) - XGBoost')
plt.legend()
plt.show()

# Plot 3: Predicted vs Actual CO2 (Testing Data)
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_test_xgb, color='red', alpha=0.6, label='Testing Data')
plt.plot([y_synthetic.min(), y_synthetic.max()], [y_synthetic.min(), y_synthetic.max()], 'k--', lw=2)
plt.xlabel('Actual CO2')
plt.ylabel('Predicted CO2')
plt.title('Predicted vs Actual CO2 (Testing Data) - XGBoost')
plt.legend()
plt.show()

# Plot 4: Residuals Plot (Testing Data)
residuals_test_xgb = y_test - y_pred_test_xgb
plt.figure(figsize=(8, 6))
plt.scatter(y_pred_test_xgb, residuals_test_xgb, color='red', alpha=0.6, label='Testing Residuals')
plt.hlines(0, y_pred_test_xgb.min(), y_pred_test_xgb.max(), colors='k', linestyles='--')
plt.xlabel('Predicted CO2')
plt.ylabel('Residuals (Actual - Predicted)')
plt.title('Residuals Plot (Testing Data) - XGBoost')
plt.legend()
plt.show()
